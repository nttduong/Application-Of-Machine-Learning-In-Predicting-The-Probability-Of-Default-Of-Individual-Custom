{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Essay_WOE.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXrg3QRLGS6U","executionInfo":{"status":"ok","timestamp":1652092162254,"user_tz":-420,"elapsed":17125,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"c269cfd2-e29e-4d21-b371-57a7ca1171ae"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"paYgfhjqNSvX","executionInfo":{"status":"ok","timestamp":1652092191075,"user_tz":-420,"elapsed":28829,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"5555d359-888f-4a2d-cdd0-cf38c49f24dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting autoimpute\n","  Downloading autoimpute-0.12.3-py3-none-any.whl (97 kB)\n","\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 40 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 51 kB 3.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 61 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 71 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 81 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 97 kB 2.8 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autoimpute) (1.3.5)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from autoimpute) (0.11.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from autoimpute) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from autoimpute) (1.0.2)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from autoimpute) (0.90)\n","Requirement already satisfied: missingno in /usr/local/lib/python3.7/dist-packages (from autoimpute) (0.5.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from autoimpute) (1.4.1)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from autoimpute) (0.10.2)\n","Requirement already satisfied: pymc3 in /usr/local/lib/python3.7/dist-packages (from autoimpute) (3.11.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from missingno->autoimpute) (3.2.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->missingno->autoimpute) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->missingno->autoimpute) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->missingno->autoimpute) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->missingno->autoimpute) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->missingno->autoimpute) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->missingno->autoimpute) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autoimpute) (2022.1)\n","Requirement already satisfied: semver>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from pymc3->autoimpute) (2.13.0)\n","Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pymc3->autoimpute) (4.2.4)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pymc3->autoimpute) (0.5.2)\n","Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pymc3->autoimpute) (1.0.2)\n","Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pymc3->autoimpute) (0.12.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pymc3->autoimpute) (0.3.4)\n","Requirement already satisfied: theano-pymc==1.1.2 in /usr/local/lib/python3.7/dist-packages (from pymc3->autoimpute) (1.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from theano-pymc==1.1.2->pymc3->autoimpute) (3.6.0)\n","Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pymc3->autoimpute) (57.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pymc3->autoimpute) (21.3)\n","Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pymc3->autoimpute) (0.18.2)\n","Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pymc3->autoimpute) (1.5.8)\n","Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pymc3->autoimpute) (1.6.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autoimpute) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autoimpute) (1.1.0)\n","Installing collected packages: autoimpute\n","Successfully installed autoimpute-0.12.3\n","Collecting fancyimpute\n","  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n","Collecting knnimpute>=0.1.0\n","  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n","Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.0.2)\n","Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.0.31)\n","Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (1.2.7)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from fancyimpute) (3.6.4)\n","Collecting nose\n","  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n","\u001b[K     |████████████████████████████████| 154 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.15.0)\n","Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.1.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (0.70.12.2)\n","Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (0.6.2.post0)\n","Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (3.2.0)\n","Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy->fancyimpute) (2.0.10)\n","Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.5.post2)\n","Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy->fancyimpute) (0.3.4)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (21.4.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (57.4.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (1.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (1.11.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->fancyimpute) (8.12.0)\n","Building wheels for collected packages: fancyimpute, knnimpute\n","  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29899 sha256=ee25d8be2c82c99116613c11bf3189ab19bc1479c0c7c7a35dc61cfa7d301049\n","  Stored in directory: /root/.cache/pip/wheels/e3/04/06/a1a7d89ef4e631ce6268ea2d8cde04f7290651c1ff1025ce68\n","  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11353 sha256=1b02c27b4efdfaa55d7c6f00578c1fcb953567c87a3e2d279176bc5f0d7c9934\n","  Stored in directory: /root/.cache/pip/wheels/72/21/a8/a045cacd9838abd5643f6bfa852c0796a99d6b1494760494e0\n","Successfully built fancyimpute knnimpute\n","Installing collected packages: nose, knnimpute, fancyimpute\n","Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n","Collecting xverse\n","  Downloading xverse-1.0.5-py3-none-any.whl (21 kB)\n","Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from xverse) (1.3.5)\n","Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from xverse) (1.0.2)\n","Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from xverse) (0.10.2)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from xverse) (1.21.6)\n","Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from xverse) (1.4.1)\n","Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from xverse) (3.2.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->xverse) (3.0.8)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->xverse) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->xverse) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.3->xverse) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.3->xverse) (4.2.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->xverse) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.3->xverse) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->xverse) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->xverse) (1.1.0)\n","Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.6.1->xverse) (0.5.2)\n","Installing collected packages: xverse\n","Successfully installed xverse-1.0.5\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import scipy\n","from scipy.stats import chi2\n","from scipy.stats import chi2_contingency\n","from scipy.stats import pearsonr, spearmanr\n","import pandas.core.algorithms as algos\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib.gridspec as gridspec \n","from pandas import Series\n","import scipy.stats.stats as stats\n","import re\n","import traceback\n","import string\n","max_bin = 20\n","force_bin = 3\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from lightgbm import LGBMClassifier\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.svm import SVC\n","from sklearn import tree\n","from sklearn.tree import export_graphviz\n","from sklearn.linear_model import Perceptron\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import  precision_recall_curve, roc_auc_score, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score,auc, roc_curve, plot_confusion_matrix, classification_report\n","from IPython.display import Image\n","import pydotplus\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","color = sns.color_palette()\n","seed = 42\n","!pip install autoimpute\n","!pip install fancyimpute\n","\n","from sklearn.impute import SimpleImputer\n","import time\n","import gc\n","!pip install xverse"]},{"cell_type":"code","source":["def application_train_test(num_rows = None, nan_as_category = False):\n","    # Read data and merge\n","    df = pd.read_csv('/content/drive/MyDrive/application_train.csv', nrows= num_rows)\n","    test_df = pd.read_csv('/content/drive/MyDrive/application_test.csv', nrows= num_rows)\n","    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n","    df = df.append(test_df).reset_index()\n","    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n","    df = df[df['CODE_GENDER'] != 'XNA']\n","    \n","    # Categorical features with Binary encode (0 or 1; two categories)\n","    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n","        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n","    # Categorical features with One-Hot encode\n","    df, cat_cols = one_hot_encoder(df, nan_as_category)\n","    \n","    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n","    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n","    # Some simple new features (percentages)\n","    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n","    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n","    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n","    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n","    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n","    del test_df\n","    gc.collect()\n","    return df\n","\n","def bureau_and_balance(num_rows = None, nan_as_category = True):\n","    bureau = pd.read_csv('/content/drive/MyDrive/bureau.csv', nrows = num_rows)\n","    bb = pd.read_csv('/content/drive/MyDrive/bureau_balance.csv', nrows = num_rows)\n","    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n","    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n","    \n","    # Bureau balance: Perform aggregations and merge with bureau.csv\n","    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n","    for col in bb_cat:\n","        bb_aggregations[col] = ['mean']\n","    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n","    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n","    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n","    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n","    del bb, bb_agg\n","    gc.collect()\n","\n","    # Bureau and bureau_balance numeric features\n","    num_aggregations = {\n","        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n","        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n","        'DAYS_CREDIT_UPDATE': ['mean'],\n","        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n","        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n","        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n","        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n","        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n","        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n","        'AMT_ANNUITY': ['max', 'mean'],\n","        'CNT_CREDIT_PROLONG': ['sum'],\n","        'MONTHS_BALANCE_MIN': ['min'],\n","        'MONTHS_BALANCE_MAX': ['max'],\n","        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n","    }\n","    # Bureau and bureau_balance categorical features\n","    cat_aggregations = {}\n","    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n","    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n","    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n","    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n","    # Bureau: Active credits - using only numerical aggregations\n","    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n","    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n","    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n","    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n","    del active, active_agg\n","    gc.collect()\n","    # Bureau: Closed credits - using only numerical aggregations\n","    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n","    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n","    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n","    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n","    del closed, closed_agg, bureau\n","    gc.collect()\n","    return bureau_agg  \n","\n","def previous_applications(num_rows = None, nan_as_category = True):\n","    prev = pd.read_csv('/content/drive/MyDrive/previous_application.csv', nrows = num_rows)\n","    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n","    # Days 365.243 values -> nan\n","    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n","    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n","    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n","    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n","    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n","    # Add feature: value ask / value received percentage\n","    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n","    # Previous applications numeric features\n","    num_aggregations = {\n","        'AMT_ANNUITY': ['min', 'max', 'mean'],\n","        'AMT_APPLICATION': ['min', 'max', 'mean'],\n","        'AMT_CREDIT': ['min', 'max', 'mean'],\n","        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n","        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n","        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n","        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n","        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n","        'DAYS_DECISION': ['min', 'max', 'mean'],\n","        'CNT_PAYMENT': ['mean', 'sum'],\n","    }\n","\n","    # Previous applications categorical features\n","    cat_aggregations = {}\n","    for cat in cat_cols:\n","        cat_aggregations[cat] = ['mean']\n","    \n","    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n","    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n","    # Previous Applications: Approved Applications - only numerical features\n","    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n","    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n","    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n","    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n","    # Previous Applications: Refused Applications - only numerical features\n","    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n","    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n","    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n","    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n","    del refused, refused_agg, approved, approved_agg, prev\n","    gc.collect()\n","    return prev_agg\n","\n","def pos_cash(num_rows = None, nan_as_category = True):\n","    pos = pd.read_csv('/content/drive/MyDrive/POS_CASH_balance.csv', nrows = num_rows)\n","    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n","    # Features\n","    aggregations = {\n","        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n","        'SK_DPD': ['max', 'mean'],\n","        'SK_DPD_DEF': ['max', 'mean']\n","    }\n","    for cat in cat_cols:\n","        aggregations[cat] = ['mean']\n","    \n","    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n","    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n","    # Count pos cash accounts\n","    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n","    del pos\n","    gc.collect()\n","    return pos_agg\n","\n","def installments_payments(num_rows = None, nan_as_category = True):\n","    ins = pd.read_csv('/content/drive/MyDrive/installments_payments.csv', nrows = num_rows)\n","    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n","    # Percentage and difference paid in each installment (amount paid and installment value)\n","    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n","    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n","    # Days past due and days before due (no negative values)\n","    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n","    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n","    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n","    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n","    # Features: Perform aggregations\n","    aggregations = {\n","        'NUM_INSTALMENT_VERSION': ['nunique'],\n","        'DPD': ['max', 'mean', 'sum'],\n","        'DBD': ['max', 'mean', 'sum'],\n","        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n","        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n","        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n","        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n","        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n","    }\n","\n","    for cat in cat_cols:\n","        aggregations[cat] = ['mean']\n","    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n","    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n","    # Count installments accounts\n","    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n","    del ins\n","    gc.collect()\n","    return ins_agg\n","\n","def credit_card_balance(num_rows = None, nan_as_category = True):\n","    cc = pd.read_csv('/content/drive/MyDrive/credit_card_balance.csv', nrows = num_rows)\n","    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n","    # General aggregations\n","    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n","    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n","    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n","    # Count credit card lines\n","    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n","    del cc\n","    gc.collect()\n","    return cc_agg\n"],"metadata":{"id":"IU90576cJv7d","executionInfo":{"status":"ok","timestamp":1652092294772,"user_tz":-420,"elapsed":445,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#resampling\n","# umbalanced data\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import SMOTE\n","def fill_missing(df): \n","  column = [col for col in df.columns]\n","  df[column] = df[column].fillna(df[column].mode().iloc[0])\n","  return df\n","\n","def one_hot_encoder(df, nan_as_category = True):\n","    original_columns = list(df.columns)\n","    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n","    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n","    new_columns = [c for c in df.columns if c not in original_columns]\n","    return df, new_columns\n","def over_sampling(X, y):\n","  ros = RandomOverSampler(random_state=25)\n","  X_ros, y_ros = ros.fit_resample(X, y)\n","  return X_ros, y_ros \n","def under_sampling(X, y):\n","  rus = RandomUnderSampler(random_state = 42, replacement = True)\n","  X_rus, y_rus = rus.fit_resample(X, y)\n","  return X_rus, y_rus\n","def smothing(X, y):\n","  smote = SMOTE()\n","  X_smote, y_smote = smote.fit_resample(X, y)\n","  return X_smote, y_smote\n","\n","#Modeling\n","#Chia data\n","from sklearn.model_selection import train_test_split\n","def split_data(X,y):\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","    return X_train, X_val, y_train, y_val \n","\n","#Scaling data (Tìm hiểu xem có những cách scaling nào)\n","from sklearn.preprocessing import StandardScaler\n","def scale(X_train, X_val):\n","    sc_X = StandardScaler()\n","    X_train = sc_X.fit_transform(X_train)\n","    X_val = sc_X.transform(X_val)\n","    return X_train, X_val\n","\n","from sklearn.preprocessing import MinMaxScaler\n","def scale_minmax(X_train, X_val):\n","  scaler_minmax = MinMaxScaler()\n","  X_train = scaler_minmax.fit_transform(X_train)\n","  X_val = scaler_minmax.transform(X_val)\n","  return X_train, X_val\n","\n","\n","# Model\n","def metrics(model, X_val, y_val):\n","  y_pred = model.predict(X_val)\n","  ypred_prob = model.predict_proba(X_val)[:,1]\n","  target_names = [\"Class 0\", \"Class 1\"]\n","  print(\"AUC\",roc_auc_score(y_val, ypred_prob))\n","  print(classification_report(y_val, y_pred, target_names=target_names))\n","  return None\n","  \n","#print(\"Classification Accuracy:\", round(accuracy_score(y_val, y_pred)*100,2)) \n","#print(\"Precision_score is\", round(precision_score(y_val, y_pred)*100,2))\n","#print(\"Recall score\", round(recall_score(y_val,y_pred)*100,2))\n","#print(\"F1 score: \", round(f1_score(y_val,y_pred, average = \"weighted\") * 100,2))\n","\n","## Logistic Regression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import make_classification\n","import lightgbm as lgb\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.datasets import make_blobs\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import GridSearchCV\n","\n","def log(X_train,y_train,X_val, y_val):\n","  log = LogisticRegression()\n","  model = log.fit(X_train, y_train)\n","  y_predict = log.predict(X_val)\n","  a = metrics(model,X_val,y_val)\n","  return model\n","\n"," \n","\n","\n","## Random Forest\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import make_classification\n","\n","def model_random_forest(X_train, y_train, X_val, y_val): \n","  clf = RandomForestClassifier(criterion=\"gini\",\\\n","                               random_state = 25,\\\n","                               min_samples_leaf=5)\n","  model = clf.fit(X_train, y_train)\n","  y_predict = clf.predict(X_val)\n","  a = metrics(model,X_val,y_val)\n","  return model\n","\n","def rf(X_train,y_train,X_val):\n","  n_estimators = [5,20,50,100] \n","  max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n","  max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n","  min_samples_split = [2, 6, 10] # minimum sample number to split a node\n","  min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n","  bootstrap = [True, False] # method used to sample data points\n","\n","  random_grid = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}\n","  from sklearn.ensemble import RandomForestRegressor\n","  rf = RandomForestRegressor()\n","  from sklearn.model_selection import RandomizedSearchCV\n","  rf_random = RandomizedSearchCV(estimator = rf,param_distributions = random_grid,\n","               n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n","  rf_random.fit(X_train, y_train)\n","  print('Best Parameters: ', rf_random.best_params_, ' \\n')\n","  \n","\n","  #randmf = RandomForestRegressor(n_estimators = 100, min_samples_split = 6, min_samples_leaf= 4, max_features = 'sqrt', max_depth= 120, bootstrap=False) \n","  #randmf.fit( X_train, y_train)\n","  #y_pred = randmf.predict(X_val)\n","  #ypred_prob = randmf.predict_proba(X_val)[:, 1]\n","  #print(' AUC : %.6f' % ( roc_auc_score(y_val, ypred_prob)))\n","  #plot_AUC( y_val, ypred_prob)\n","  return None\n","\n","\n","## XGB\n","def xgb(X_train, y_train, X_val, y_val):\n","  import xgboost as xgb\n","  param_init = {\n","    \"objective\": \"binary:logistic\", \n","    \"booster\": \"gbtree\", \n","    \"max_depth\": 4, # default: 3 only for depthwise\n","    \"n_estimators\": 1000, # default: 500  \n","    \"learning_rate\": 0.025, # default: 0.05 \n","    \"subsample\": 0.7, \n","    \"colsample_bytree\": 0.6,  # default:  1.0\n","    \"colsample_bylevel\": 0.5, # default: 1.0\n","    \"random_state\": 0,\n","    \n","    #\n","    \"silent\": True, \n","    \"n_jobs\": 16, \n","    \n","    #\n","    \"tree_method\": \"hist\", # default: auto\n","    \"grow_policy\": \"lossguide\" # default depthwise\n","    }\n","    \n","  param_fit = {\n","    \"eval_metric\": \"auc\", \n","    \"early_stopping_rounds\": 500, # default: 100\n","    \"verbose\": 200,\n","    \"eval_set\": [(X_train, y_train), (X_val, y_val)]}\n","\n","  xgb_model = xgb.XGBClassifier(**param_init)\n","  xgb_model.fit(X_train, y_train, **param_fit)\n","  evals_result = xgb_model.evals_result()\n","\n","\n","#lightgbm\n","def model_LGBM(X_train, y_train, X_val, y_val): \n","  clf = lgb.LGBMClassifier(boosting_type = 'goss',\n","            nthread=4,\n","            n_estimators=10000,\n","            learning_rate=0.005134,\n","            num_leaves=54,\n","            colsample_bytree=0.508716,\n","            subsample=1,\n","            max_depth=10,\n","            reg_alpha=0.436193,\n","            reg_lambda=0.479169,\n","            min_split_gain=0.024766,\n","            min_child_weight=40,\n","            silent=-1,\n","            verbose=-1,\n","            is_unbalance=False)\n","  model = clf.fit(X_train, y_train)\n","  a = metrics(model,X_val,y_val)\n","  return model\n","\n","\n","\n","\n","### Chia K-fold - tuning Catboots\n","def kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n","    # Divide in training/validation and test data\n","    train_df = df[df['TARGET'].notnull()]\n","    test_df = df[df['TARGET'].isnull()]\n","    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n","    del df\n","    gc.collect()\n","    # Cross validation model\n","    if stratified:\n","        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n","    else:\n","        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n","    # Create arrays and dataframes to store results\n","    oof_preds = np.zeros(train_df.shape[0])\n","    sub_preds = np.zeros(test_df.shape[0])\n","    feature_importance_df = pd.DataFrame()\n","    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n","    \n","    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n","        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n","        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n","\n","        # LightGBM parameters found by Bayesian optimization\n","        clf = LGBMClassifier(\n","            nthread=4,\n","            n_estimators=10000,\n","            learning_rate=0.02,\n","            num_leaves=34,\n","            colsample_bytree=0.9497036,\n","            subsample=0.8715623,\n","            max_depth=8,\n","            reg_alpha=0.041545473,\n","            reg_lambda=0.0735294,\n","            min_split_gain=0.0222415,\n","            min_child_weight=39.3259775,\n","            silent=-1,\n","            verbose=-1, )\n","\n","        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n","            eval_metric= 'auc', verbose= 200, early_stopping_rounds= 200)\n","\n","        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n","        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n","\n","        fold_importance_df = pd.DataFrame()\n","        fold_importance_df[\"feature\"] = feats\n","        fold_importance_df[\"importance\"] = clf.feature_importances_\n","        fold_importance_df[\"fold\"] = n_fold + 1\n","        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n","        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n","        del clf, train_x, train_y, valid_x, valid_y\n","        gc.collect()\n","\n","    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n","    # Write submission file and plot feature importance\n","    if not debug:\n","        test_df['TARGET'] = sub_preds\n","        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n","    display_importances(feature_importance_df)\n","    return feature_importance_df\n","\n","# Display/plot feature importance\n","def display_importances(feature_importance_df_):\n","    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n","    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n","    plt.figure(figsize=(8, 10))\n","    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n","    plt.title('LightGBM Features (avg over folds)')\n","    plt.tight_layout()\n","    plt.savefig('lgbm_importances01.png')\n","\n","#Metrics Performance\n","## Đánh giá mô hình thông qua các metrics.\n","import numpy as np\n","from sklearn.metrics import  precision_recall_curve, roc_auc_score, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score,auc, roc_curve, plot_confusion_matrix\n","\n","\n","##AUC - ROC\n","def plot_AUC( y_val, ypred_prob):\n","    from sklearn import metrics\n","    fig, (ax, ax1) = plt.subplots(nrows = 1, ncols = 2, figsize = (15,5))\n","    \n","    fpr, tpr, threshold = metrics.roc_curve(y_val, ypred_prob)\n","    roc_auc = metrics.auc(fpr, tpr)\n","\n","    ax.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","    ax.plot([0, 1], [0, 1],'r--')\n","    ax.set_title('Receiver Operating Characteristic ',fontsize=10)\n","    ax.set_ylabel('True Positive Rate',fontsize=20)\n","    ax.set_xlabel('False Positive Rate',fontsize=15)\n","    ax.legend(loc = 'lower right', prop={'size': 16})\n","    plt.subplots_adjust(wspace=1)"],"metadata":{"id":"Q54sYoqbRi-E","executionInfo":{"status":"ok","timestamp":1652092298695,"user_tz":-420,"elapsed":1575,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df = application_train_test(num_rows = None, nan_as_category = False)\n","bureau = bureau_and_balance(num_rows = None, nan_as_category = True)\n","prev = previous_applications(num_rows = None, nan_as_category = True)\n","pos = pos_cash(num_rows = None, nan_as_category = True)\n","ins = installments_payments(num_rows = None, nan_as_category = True)\n","cc = credit_card_balance(num_rows = None, nan_as_category = True)"],"metadata":{"id":"VNgXSxj7KNoX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652092480771,"user_tz":-420,"elapsed":178089,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"d0249624-a254-4411-abd5-0397eb62861f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 307511, test samples: 48744\n"]}]},{"cell_type":"code","source":["df = df.join(bureau, how='left', on='SK_ID_CURR')\n","df = df.join(prev, how='left', on='SK_ID_CURR')\n","df = df.join(pos, how='left', on='SK_ID_CURR')\n","df = df.join(ins, how='left', on='SK_ID_CURR')\n","df = df.join(cc, how='left', on='SK_ID_CURR')"],"metadata":{"id":"yjJXspJlKQT8","executionInfo":{"status":"ok","timestamp":1652092488933,"user_tz":-420,"elapsed":8172,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"t9jysiwSKQxu","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1652092488933,"user_tz":-420,"elapsed":41,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"4ed581df-a47c-443c-d6d7-5785e8688192"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   index  SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n","0      0      100002     1.0            0             0                0   \n","1      1      100003     0.0            1             0                1   \n","2      2      100004     0.0            0             1                0   \n","3      3      100006     0.0            1             0                0   \n","4      4      100007     0.0            0             0                0   \n","\n","   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  ...  \\\n","0             0          202500.0    406597.5      24700.5  ...   \n","1             0          270000.0   1293502.5      35698.5  ...   \n","2             0           67500.0    135000.0       6750.0  ...   \n","3             0          135000.0    312682.5      29686.5  ...   \n","4             0          121500.0    513000.0      21865.5  ...   \n","\n","   CC_NAME_CONTRACT_STATUS_Signed_MAX  CC_NAME_CONTRACT_STATUS_Signed_MEAN  \\\n","0                                 NaN                                  NaN   \n","1                                 NaN                                  NaN   \n","2                                 NaN                                  NaN   \n","3                                 0.0                                  0.0   \n","4                                 NaN                                  NaN   \n","\n","   CC_NAME_CONTRACT_STATUS_Signed_SUM  CC_NAME_CONTRACT_STATUS_Signed_VAR  \\\n","0                                 NaN                                 NaN   \n","1                                 NaN                                 NaN   \n","2                                 NaN                                 NaN   \n","3                                 0.0                                 0.0   \n","4                                 NaN                                 NaN   \n","\n","   CC_NAME_CONTRACT_STATUS_nan_MIN  CC_NAME_CONTRACT_STATUS_nan_MAX  \\\n","0                              NaN                              NaN   \n","1                              NaN                              NaN   \n","2                              NaN                              NaN   \n","3                              0.0                              0.0   \n","4                              NaN                              NaN   \n","\n","   CC_NAME_CONTRACT_STATUS_nan_MEAN  CC_NAME_CONTRACT_STATUS_nan_SUM  \\\n","0                               NaN                              NaN   \n","1                               NaN                              NaN   \n","2                               NaN                              NaN   \n","3                               0.0                              0.0   \n","4                               NaN                              NaN   \n","\n","   CC_NAME_CONTRACT_STATUS_nan_VAR  CC_COUNT  \n","0                              NaN       NaN  \n","1                              NaN       NaN  \n","2                              NaN       NaN  \n","3                              0.0       6.0  \n","4                              NaN       NaN  \n","\n","[5 rows x 798 columns]"],"text/html":["\n","  <div id=\"df-4abe6a1e-82b1-4f9e-a9aa-cc3904d01a2b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>SK_ID_CURR</th>\n","      <th>TARGET</th>\n","      <th>CODE_GENDER</th>\n","      <th>FLAG_OWN_CAR</th>\n","      <th>FLAG_OWN_REALTY</th>\n","      <th>CNT_CHILDREN</th>\n","      <th>AMT_INCOME_TOTAL</th>\n","      <th>AMT_CREDIT</th>\n","      <th>AMT_ANNUITY</th>\n","      <th>...</th>\n","      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n","      <th>CC_NAME_CONTRACT_STATUS_Signed_MEAN</th>\n","      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n","      <th>CC_NAME_CONTRACT_STATUS_Signed_VAR</th>\n","      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n","      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n","      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n","      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n","      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n","      <th>CC_COUNT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>100002</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>202500.0</td>\n","      <td>406597.5</td>\n","      <td>24700.5</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>100003</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>270000.0</td>\n","      <td>1293502.5</td>\n","      <td>35698.5</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>100004</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>67500.0</td>\n","      <td>135000.0</td>\n","      <td>6750.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>100006</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>135000.0</td>\n","      <td>312682.5</td>\n","      <td>29686.5</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>100007</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>121500.0</td>\n","      <td>513000.0</td>\n","      <td>21865.5</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 798 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4abe6a1e-82b1-4f9e-a9aa-cc3904d01a2b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4abe6a1e-82b1-4f9e-a9aa-cc3904d01a2b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4abe6a1e-82b1-4f9e-a9aa-cc3904d01a2b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df = df.drop('index', axis = 1)"],"metadata":{"id":"vsgl9R8hNyBS","executionInfo":{"status":"ok","timestamp":1652092536852,"user_tz":-420,"elapsed":4164,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","df.to_csv('essay.csv', encoding = 'utf-8-sig') \n","files.download('essay.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"gRd0_FaNYAn4","executionInfo":{"status":"ok","timestamp":1652092686968,"user_tz":-420,"elapsed":149087,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"9b7d57c2-ee74-469e-f2d8-6f5c9d0091a8"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b372f136-c47e-467d-8fee-e559f9da3596\", \"essay.csv\", 1227099222)"]},"metadata":{}}]},{"cell_type":"code","source":["df = fill_missing(df)\n","df = df.replace((np.inf, -np.inf), 0)"],"metadata":{"id":"ufPGnTPRysLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df.drop('TARGET', axis = 1)\n","y = df.TARGET"],"metadata":{"id":"1Gx_vbmTOdc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from xverse.transformer import WOE\n","clf = WOE()\n","clf.fit(X, y)\n","clf.woe_df\n","clf.iv_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"Zr9EaFnKOaxm","executionInfo":{"status":"error","timestamp":1651982195979,"user_tz":-420,"elapsed":311,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"9cf99b66-e035-4431-ebb2-1e9a20c80f6d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-b642c19cc8d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxverse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWOE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWOE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwoe_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miv_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xverse/transformer/_woe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             raise ValueError(\"The target column y must be binary. But the target contains \" + str(len(unique)) + \\\n\u001b[0;32m--> 129\u001b[0;31m                              \" unique value(s).\")\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;31m#apply monotonic binning operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The target column y must be binary. But the target contains 3 unique value(s)."]}]},{"cell_type":"code","source":["iv = clf.iv_df\n","iv_1 = iv[iv['Information_Value']>0.02]\n","iv_1['Variable_Name']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-7Czc-DQ8If","executionInfo":{"status":"ok","timestamp":1651853237574,"user_tz":-420,"elapsed":310,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"a70d85c1-837a-437e-ff7c-7a5dd1652169"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["171                      EXT_SOURCE_2\n","172                      EXT_SOURCE_3\n","63              BURO_DAYS_CREDIT_MEAN\n","170                      EXT_SOURCE_1\n","65       BURO_DAYS_CREDIT_UPDATE_MEAN\n","                    ...              \n","212         INSTAL_AMT_INSTALMENT_MAX\n","522        REGION_POPULATION_RELATIVE\n","156    CLOSED_DAYS_CREDIT_ENDDATE_MAX\n","216     INSTAL_DAYS_ENTRY_PAYMENT_SUM\n","341                      PAYMENT_RATE\n","Name: Variable_Name, Length: 67, dtype: object"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["iv_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"4duf_Q-SQSGy","executionInfo":{"status":"ok","timestamp":1651853287058,"user_tz":-420,"elapsed":520,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"81c15e0a-e5e5-4532-896f-72921dc4f4dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      Variable_Name  Information_Value\n","171                    EXT_SOURCE_2           0.247521\n","172                    EXT_SOURCE_3           0.171841\n","63            BURO_DAYS_CREDIT_MEAN           0.105685\n","170                    EXT_SOURCE_1           0.085756\n","65     BURO_DAYS_CREDIT_UPDATE_MEAN           0.084407\n","..                              ...                ...\n","212       INSTAL_AMT_INSTALMENT_MAX           0.020582\n","522      REGION_POPULATION_RELATIVE           0.020442\n","156  CLOSED_DAYS_CREDIT_ENDDATE_MAX           0.020319\n","216   INSTAL_DAYS_ENTRY_PAYMENT_SUM           0.020199\n","341                    PAYMENT_RATE           0.020118\n","\n","[67 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-783c44f5-7ffa-41d1-88fa-ff3b50d8a7bd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Variable_Name</th>\n","      <th>Information_Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>171</th>\n","      <td>EXT_SOURCE_2</td>\n","      <td>0.247521</td>\n","    </tr>\n","    <tr>\n","      <th>172</th>\n","      <td>EXT_SOURCE_3</td>\n","      <td>0.171841</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>BURO_DAYS_CREDIT_MEAN</td>\n","      <td>0.105685</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>EXT_SOURCE_1</td>\n","      <td>0.085756</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>BURO_DAYS_CREDIT_UPDATE_MEAN</td>\n","      <td>0.084407</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>212</th>\n","      <td>INSTAL_AMT_INSTALMENT_MAX</td>\n","      <td>0.020582</td>\n","    </tr>\n","    <tr>\n","      <th>522</th>\n","      <td>REGION_POPULATION_RELATIVE</td>\n","      <td>0.020442</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>CLOSED_DAYS_CREDIT_ENDDATE_MAX</td>\n","      <td>0.020319</td>\n","    </tr>\n","    <tr>\n","      <th>216</th>\n","      <td>INSTAL_DAYS_ENTRY_PAYMENT_SUM</td>\n","      <td>0.020199</td>\n","    </tr>\n","    <tr>\n","      <th>341</th>\n","      <td>PAYMENT_RATE</td>\n","      <td>0.020118</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>67 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-783c44f5-7ffa-41d1-88fa-ff3b50d8a7bd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-783c44f5-7ffa-41d1-88fa-ff3b50d8a7bd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-783c44f5-7ffa-41d1-88fa-ff3b50d8a7bd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["X=df[[col for col in iv_1['Variable_Name']]]\n","X = clf.transform(X)\n","y = df.TARGET"],"metadata":{"id":"tCpQCpePROxt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_val, y_train, y_val = split_data(X,y)\n","#Sampling\n","X_ros, y_ros = over_sampling(X_train, y_train)\n","X_rus, y_rus = under_sampling(X_train, y_train)\n","X_smooth, y_smooth = smothing(X_train, y_train)"],"metadata":{"id":"gTaPtcHCRyr_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log(X_train, y_train, X_val, y_val)"],"metadata":{"id":"dCirgMH_SpRo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651853480202,"user_tz":-420,"elapsed":6251,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"29ddcbd6-2fd2-43d1-c23d-2d364411ee5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AUC 0.7409154239114759\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.92      1.00      0.96     50928\n","     Class 1       0.53      0.00      0.01      4429\n","\n","    accuracy                           0.92     55357\n","   macro avg       0.72      0.50      0.48     55357\n","weighted avg       0.89      0.92      0.88     55357\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression()"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["print(\"Oversampling:\")\n","model1 = log(X_ros, y_ros, X_val, y_val)\n","print(\"\\nUndersampling:\")\n","model2 = log(X_rus, y_rus, X_val, y_val)\n","print(\"\\nSmote: \")\n","model3 = log(X_smooth, y_smooth, X_val, y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EivLnE0xR2vT","executionInfo":{"status":"ok","timestamp":1651853617437,"user_tz":-420,"elapsed":25153,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"537b7660-9c23-47bb-920d-c18b54aa21ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Oversampling:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["AUC 0.741480971600156\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.96      0.68      0.79     50928\n","     Class 1       0.16      0.68      0.25      4429\n","\n","    accuracy                           0.68     55357\n","   macro avg       0.56      0.68      0.52     55357\n","weighted avg       0.90      0.68      0.75     55357\n","\n","\n","Undersampling:\n","AUC 0.7411119790541689\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.96      0.68      0.79     50928\n","     Class 1       0.15      0.68      0.25      4429\n","\n","    accuracy                           0.68     55357\n","   macro avg       0.56      0.68      0.52     55357\n","weighted avg       0.90      0.68      0.75     55357\n","\n","\n","Smote: \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"]},{"output_type":"stream","name":"stdout","text":["AUC 0.7351036028923411\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.96      0.69      0.80     50928\n","     Class 1       0.16      0.66      0.25      4429\n","\n","    accuracy                           0.68     55357\n","   macro avg       0.56      0.67      0.53     55357\n","weighted avg       0.89      0.68      0.76     55357\n","\n"]}]},{"cell_type":"code","source":["#Hyperparameters tuning with randomsearchcv\n","def randomsearchcv_lgbm(X_train, y_train, X_val, y_val):\n","  clf = lgb.LGBMClassifier()\n","  param_dist = { \"learning_rate\": np.linspace(0,0.2,5),\n","               \"max_depth\": randint(3, 10),\n","                \"min_split_gain\": np.linspace(1, 10, 1),\n","                \"num_iterations\": randint(100, 10000),\n","                \"min_data_in_leaf\": randint(3, 10),\n","                \"min_gain_to_split\": randint(1, 10),\n","                \"max_bin\": randint(10, 100)}\n","               \n","  rscv = RandomizedSearchCV(clf , param_dist, scoring='accuracy', cv =5)\n","  rscv.fit(X_train,y_train)\n","  best_params = rscv.best_estimator_\n","  y_predict = best_params.predict(X_val)\n","  y_predict_proba = best_params.predict_proba(X_val)[:, 1]\n","  a = metrics(rscv,X_val,y_val)\n","  return rscv\n","\n","!pip3 install catboost\n","from catboost import CatBoostClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","def randomsearchcv_catboost(X_train, y_train, X_val, y_val):\n","  clf = CatBoostClassifier()\n","  param_dist = { \"learning_rate\": np.linspace(0,0.2,5),\n","               \"max_depth\": randint(3, 10),\n","                \"iterations\": randint(10, 100)}\n","               \n","  rscv = RandomizedSearchCV(clf , param_dist, scoring='accuracy', cv =5)\n","  rscv.fit(X_train,y_train)\n","  best_params = rscv.best_estimator_\n","  y_predict = best_params.predict(X_val)\n","  y_predict_proba = best_params.predict_proba(X_val)[:, 1]\n","  a = metrics(rscv,X_val,y_val)\n","  return rscv"],"metadata":{"id":"8mmcL-gTR-05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651857104882,"user_tz":-420,"elapsed":3785,"user":{"displayName":"Atlas42","userId":"17459591258149822456"}},"outputId":"d629a674-fd94-444f-8cc7-3f429b5d9edd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.2.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n"]}]},{"cell_type":"code","source":["y = df.TARGET\n","X = df.drop('TARGET', axis = 1)\n","X_train, X_val, y_train, y_val = split_data(X,y)\n","X_train, X_val = scale(X_train, X_val)\n","#Sampling\n","X_ros, y_ros = over_sampling(X_train, y_train)\n","X_rus, y_rus = under_sampling(X_train, y_train)\n","X_smooth, y_smooth = smothing(X_train, y_train)"],"metadata":{"id":"16zYXPhRspSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rscv_catboost_ros = randomsearchcv_catboost(X_ros, y_ros, X_val, y_val)"],"metadata":{"id":"Nmt8YOWiTBgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rscv_catboost_rus = randomsearchcv_catboost(X_rus, y_rus, X_val, y_val)"],"metadata":{"id":"_0LVNWAktn1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rscv_catboost_smooth = randomsearchcv_catboost(X_smooth, y_smooth, X_val, y_val)"],"metadata":{"id":"1cuB9NZWt1hG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rscv_lgbm_ros = randomsearchcv_lgbm(X_ros, y_ros, X_val, y_val)"],"metadata":{"id":"_zbArU5zW0Gf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rscv_lgbm_rus = randomsearchcv_lgbm(X_rus, y_rus, X_val, y_val)"],"metadata":{"id":"zVr74zPkuIi9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rscv_lgbm_smooth = randomsearchcv_lgbm(X_smooth, y_smooth, X_val, y_val)"],"metadata":{"id":"-D8yNRM1uMH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feat_importance = kfold_lightgbm(df, num_folds= 10, stratified= False)"],"metadata":{"id":"EL-QqURbsjZh"},"execution_count":null,"outputs":[]}]}